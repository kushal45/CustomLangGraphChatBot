{
    "LangGraph State Model": {
      "prefix": "lg-state",
      "body": [
        "from typing import TypedDict, List, Optional, Dict, Any",
        "from langchain_core.messages import BaseMessage",
        "",
        "class ${1:ReviewState}(TypedDict):",
        "    \"\"\"State for the ${1:ReviewState} workflow.\"\"\"",
        "    messages: List[BaseMessage]",
        "    ${2:repository_url}: str",
        "    ${3:analysis_results}: Optional[Dict[str, Any]]",
        "    ${4:current_step}: str",
        "    ${5:error_message}: Optional[str]"
      ],
      "description": "Create a LangGraph state model"
    },
    "LangGraph Node Function": {
      "prefix": "lg-node",
      "body": [
        "async def ${1:node_name}(state: ${2:ReviewState}) -> Dict[str, Any]:",
        "    \"\"\"${3:Node description}.",
        "    ",
        "    Args:",
        "        state: Current workflow state",
        "        ",
        "    Returns:",
        "        Updated state dictionary",
        "    \"\"\"",
        "    try:",
        "        logger.info(f\"Executing ${1:node_name} node\")",
        "        ",
        "        # ${4:Node implementation}",
        "        ",
        "        return {",
        "            \"${5:result_key}\": ${6:result_value},",
        "            \"current_step\": \"${1:node_name}_complete\"",
        "        }",
        "    except Exception as e:",
        "        logger.error(f\"Error in ${1:node_name}: {str(e)}\")",
        "        return {",
        "            \"error_message\": str(e),",
        "            \"current_step\": \"error\"",
        "        }"
      ],
      "description": "Create a LangGraph node function"
    },
    "LangGraph Conditional Edge": {
      "prefix": "lg-condition",
      "body": [
        "def ${1:should_continue}(state: ${2:ReviewState}) -> str:",
        "    \"\"\"${3:Determine next step based on state}.",
        "    ",
        "    Args:",
        "        state: Current workflow state",
        "        ",
        "    Returns:",
        "        Next node name",
        "    \"\"\"",
        "    if state.get(\"error_message\"):",
        "        return \"error_handler\"",
        "    ",
        "    if ${4:condition}:",
        "        return \"${5:next_node}\"",
        "    else:",
        "        return \"${6:alternative_node}\""
      ],
      "description": "Create a conditional edge function"
    },
    "GitHub API Tool": {
      "prefix": "gh-tool",
      "body": [
        "from langchain.tools import BaseTool",
        "from typing import Optional, Type",
        "from pydantic import BaseModel, Field",
        "",
        "class ${1:GitHubToolInput}(BaseModel):",
        "    \"\"\"Input for ${1:GitHubTool}.\"\"\"",
        "    ${2:param}: str = Field(description=\"${3:Parameter description}\")",
        "",
        "class ${4:GitHubTool}(BaseTool):",
        "    \"\"\"${5:Tool description}.\"\"\"",
        "    name = \"${6:tool_name}\"",
        "    description = \"${7:Tool description for AI}\"",
        "    args_schema: Type[BaseModel] = ${1:GitHubToolInput}",
        "    ",
        "    def _run(self, ${2:param}: str) -> str:",
        "        \"\"\"${8:Execute the tool}.\"\"\"",
        "        try:",
        "            # ${9:Tool implementation}",
        "            return f\"${10:Success message}\"",
        "        except Exception as e:",
        "            logger.error(f\"Error in ${4:GitHubTool}: {str(e)}\")",
        "            return f\"Error: {str(e)}\"",
        "    ",
        "    async def _arun(self, ${2:param}: str) -> str:",
        "        \"\"\"${11:Async execute the tool}.\"\"\"",
        "        return self._run(${2:param})"
      ],
      "description": "Create a GitHub API tool"
    },
    "Code Analysis Function": {
      "prefix": "code-analysis",
      "body": [
        "import ast",
        "from typing import List, Dict, Any",
        "",
        "def analyze_${1:python}_code(file_path: str, content: str) -> Dict[str, Any]:",
        "    \"\"\"Analyze ${1:python} code for quality and issues.",
        "    ",
        "    Args:",
        "        file_path: Path to the file being analyzed",
        "        content: File content as string",
        "        ",
        "    Returns:",
        "        Analysis results dictionary",
        "    \"\"\"",
        "    try:",
        "        tree = ast.parse(content)",
        "        ",
        "        analysis = {",
        "            \"file_path\": file_path,",
        "            \"language\": \"${1:python}\",",
        "            \"lines_of_code\": len(content.splitlines()),",
        "            \"complexity\": calculate_complexity(tree),",
        "            \"issues\": find_code_issues(tree),",
        "            \"suggestions\": generate_suggestions(tree),",
        "            \"quality_score\": calculate_quality_score(tree)",
        "        }",
        "        ",
        "        return analysis",
        "    except SyntaxError as e:",
        "        return {",
        "            \"file_path\": file_path,",
        "            \"error\": f\"Syntax error: {str(e)}\",",
        "            \"quality_score\": 0",
        "        }"
      ],
      "description": "Create a code analysis function"
    },
    "Async GitHub Repository Handler": {
      "prefix": "gh-repo",
      "body": [
        "import aiohttp",
        "import asyncio",
        "from typing import Dict, List, Optional",
        "",
        "class GitHubRepository:",
        "    \"\"\"Handle GitHub repository operations.\"\"\"",
        "    ",
        "    def __init__(self, token: str, repo_url: str):",
        "        self.token = token",
        "        self.repo_url = repo_url",
        "        self.session: Optional[aiohttp.ClientSession] = None",
        "    ",
        "    async def __aenter__(self):",
        "        self.session = aiohttp.ClientSession(",
        "            headers={\"Authorization\": f\"token {self.token}\"}",
        "        )",
        "        return self",
        "    ",
        "    async def __aexit__(self, exc_type, exc_val, exc_tb):",
        "        if self.session:",
        "            await self.session.close()",
        "    ",
        "    async def ${1:get_repository_info}(self) -> Dict[str, Any]:",
        "        \"\"\"${2:Get repository information}.\"\"\"",
        "        async with self.session.get(f\"{self.repo_url}\") as response:",
        "            if response.status == 200:",
        "                return await response.json()",
        "            else:",
        "                raise Exception(f\"Failed to fetch repo info: {response.status}\")"
      ],
      "description": "Create async GitHub repository handler"
    },
    "LangGraph Workflow Builder": {
      "prefix": "lg-workflow",
      "body": [
        "from langgraph.graph import StateGraph, END",
        "from langgraph.prebuilt import ToolExecutor",
        "",
        "def create_${1:review}_workflow() -> StateGraph:",
        "    \"\"\"Create the ${1:review} workflow graph.\"\"\"",
        "    ",
        "    # Initialize the graph",
        "    workflow = StateGraph(${2:ReviewState})",
        "    ",
        "    # Add nodes",
        "    workflow.add_node(\"${3:start_review}\", ${3:start_review}_node)",
        "    workflow.add_node(\"${4:analyze_code}\", ${4:analyze_code}_node)",
        "    workflow.add_node(\"${5:generate_report}\", ${5:generate_report}_node)",
        "    workflow.add_node(\"error_handler\", error_handler_node)",
        "    ",
        "    # Add edges",
        "    workflow.set_entry_point(\"${3:start_review}\")",
        "    workflow.add_edge(\"${3:start_review}\", \"${4:analyze_code}\")",
        "    workflow.add_conditional_edges(",
        "        \"${4:analyze_code}\",",
        "        ${6:should_continue},",
        "        {",
        "            'continue': \"${5:generate_report}\",",
        "            'error': \"error_handler\"",
        "        }",
        "    )",
        "    workflow.add_edge(\"${5:generate_report}\", END)",
        "    workflow.add_edge(\"error_handler\", END)",
        "    ",
        "    return workflow"
      ],
      "description": "Create a complete LangGraph workflow"
    },
    "Pydantic Model for Code Review": {
      "prefix": "review-model",
      "body": [
        "from pydantic import BaseModel, Field, validator",
        "from typing import List, Optional, Dict, Any",
        "from datetime import datetime",
        "from enum import Enum",
        "",
        "class ${1:Severity}(str, Enum):",
        "    \"\"\"Issue severity levels.\"\"\"",
        "    LOW = \"low\"",
        "    MEDIUM = \"medium\"",
        "    HIGH = \"high\"",
        "    CRITICAL = \"critical\"",
        "",
        "class ${2:CodeIssue}(BaseModel):",
        "    \"\"\"Represents a code issue found during review.\"\"\"",
        "    file_path: str = Field(..., description=\"Path to the file with the issue\")",
        "    line_number: int = Field(..., description=\"Line number where issue occurs\")",
        "    severity: ${1:Severity} = Field(..., description=\"Issue severity level\")",
        "    category: str = Field(..., description=\"Issue category (e.g., 'style', 'bug', 'security')\")",
        "    message: str = Field(..., description=\"Issue description\")",
        "    suggestion: Optional[str] = Field(None, description=\"Suggested fix\")",
        "    rule_id: Optional[str] = Field(None, description=\"Rule or check that triggered this issue\")",
        "",
        "class ${3:ReviewResult}(BaseModel):",
        "    \"\"\"Complete code review results.\"\"\"",
        "    repository_url: str",
        "    commit_hash: Optional[str] = None",
        "    review_date: datetime = Field(default_factory=datetime.now)",
        "    issues: List[${2:CodeIssue}] = Field(default_factory=list)",
        "    overall_score: float = Field(..., ge=0.0, le=10.0)",
        "    summary: str",
        "    recommendations: List[str] = Field(default_factory=list)",
        "    ",
        "    @validator('overall_score')",
        "    def validate_score(cls, v):",
        "        return round(v, 2)"
      ],
      "description": "Create Pydantic models for code review"
    },
    "FastAPI Endpoint for Review": {
      "prefix": "api-endpoint",
      "body": [
        "from fastapi import APIRouter, HTTPException, BackgroundTasks, Depends",
        "from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials",
        "from typing import Dict, Any",
        "",
        "router = APIRouter(prefix=\"/${1:reviews}\", tags=[\"${1:reviews}\"])",
        "security = HTTPBearer()",
        "",
        "@router.post(\"/${2:start}\", response_model=${3:ReviewResponse})",
        "async def ${2:start}_review(",
        "    request: ${4:ReviewRequest},",
        "    background_tasks: BackgroundTasks,",
        "    credentials: HTTPAuthorizationCredentials = Depends(security)",
        ") -> ${3:ReviewResponse}:",
        "    \"\"\"${5:Start a new code review process}.\"\"\"",
        "    try:",
        "        # Validate GitHub token",
        "        github_token = credentials.credentials",
        "        ",
        "        # Initialize review workflow",
        "        workflow = create_review_workflow()",
        "        ",
        "        # Start background task",
        "        background_tasks.add_task(",
        "            execute_review_workflow,",
        "            workflow,",
        "            request.repository_url,",
        "            github_token",
        "        )",
        "        ",
        "        return ${3:ReviewResponse}(",
        "            review_id=generate_review_id(),",
        "            status=\"started\",",
        "            message=\"Review process initiated\"",
        "        )",
        "    except Exception as e:",
        "        logger.error(f\"Error starting review: {str(e)}\")",
        "        raise HTTPException(status_code=500, detail=str(e))"
      ],
      "description": "Create FastAPI endpoint for code review"
    },
    "Error Handler Node": {
      "prefix": "lg-error",
      "body": [
        "async def error_handler_node(state: ${1:ReviewState}) -> Dict[str, Any]:",
        "    \"\"\"Handle errors in the workflow.\"\"\"",
        "    error_message = state.get(\"error_message\", \"Unknown error occurred\")",
        "    logger.error(f\"Workflow error: {error_message}\")",
        "    ",
        "    # Attempt recovery or graceful degradation",
        "    recovery_actions = []",
        "    ",
        "    if \"rate limit\" in error_message.lower():",
        "        recovery_actions.append(\"Wait for rate limit reset\")",
        "        recovery_actions.append(\"Retry with exponential backoff\")",
        "    elif \"authentication\" in error_message.lower():",
        "        recovery_actions.append(\"Check GitHub token validity\")",
        "        recovery_actions.append(\"Refresh authentication credentials\")",
        "    else:",
        "        recovery_actions.append(\"Log error for manual investigation\")",
        "        recovery_actions.append(\"Provide partial results if available\")",
        "    ",
        "    return {",
        "        \"current_step\": \"error_handled\",",
        "        \"error_handled\": True,",
        "        \"recovery_actions\": recovery_actions,",
        "        \"final_status\": \"failed_with_recovery\"",
        "    }"
      ],
      "description": "Create error handler node for LangGraph"
    },
    "GitHub Webhook Handler": {
      "prefix": "webhook-handler",
      "body": [
        "import hashlib",
        "import hmac",
        "from fastapi import Request, HTTPException",
        "",
        "async def verify_github_webhook(request: Request, secret: str) -> Dict[str, Any]:",
        "    \"\"\"Verify GitHub webhook signature and parse payload.\"\"\"",
        "    # Get signature from headers",
        "    signature = request.headers.get(\"X-Hub-Signature-256\")",
        "    if not signature:",
        "        raise HTTPException(status_code=400, detail=\"Missing signature\")",
        "    ",
        "    # Get request body",
        "    body = await request.body()",
        "    ",
        "    # Verify signature",
        "    expected_signature = \"sha256=\" + hmac.new(",
        "        secret.encode(),",
        "        body,",
        "        hashlib.sha256",
        "    ).hexdigest()",
        "    ",
        "    if not hmac.compare_digest(signature, expected_signature):",
        "        raise HTTPException(status_code=400, detail=\"Invalid signature\")",
        "    ",
        "    # Parse event type and payload",
        "    event_type = request.headers.get(\"X-GitHub-Event\")",
        "    payload = await request.json()",
        "    ",
        "    return {",
        "        \"event_type\": event_type,",
        "        \"payload\": payload,",
        "        \"repository\": payload.get(\"repository\", {}),",
        "        \"sender\": payload.get(\"sender\", {})",
        "    }"
      ],
      "description": "Create GitHub webhook verification handler"
    },
    "Code Complexity Calculator": {
      "prefix": "complexity-calc",
      "body": [
        "import ast",
        "from typing import Dict, Any",
        "",
        "class ComplexityVisitor(ast.NodeVisitor):",
        "    \"\"\"Calculate cyclomatic complexity of Python code.\"\"\"",
        "    ",
        "    def __init__(self):",
        "        self.complexity = 1  # Base complexity",
        "        self.functions = []",
        "        self.classes = []",
        "    ",
        "    def visit_FunctionDef(self, node):",
        "        \"\"\"Visit function definition.\"\"\"",
        "        func_complexity = 1",
        "        for child in ast.walk(node):",
        "            if isinstance(child, (ast.If, ast.While, ast.For, ast.AsyncFor)):",
        "                func_complexity += 1",
        "            elif isinstance(child, ast.ExceptHandler):",
        "                func_complexity += 1",
        "            elif isinstance(child, (ast.And, ast.Or)):",
        "                func_complexity += 1",
        "        ",
        "        self.functions.append({",
        "            \"name\": node.name,",
        "            \"complexity\": func_complexity,",
        "            \"line_number\": node.lineno",
        "        })",
        "        ",
        "        self.complexity += func_complexity - 1",
        "        self.generic_visit(node)",
        "    ",
        "    def visit_AsyncFunctionDef(self, node):",
        "        \"\"\"Visit async function definition.\"\"\"",
        "        self.visit_FunctionDef(node)",
        "",
        "def calculate_complexity(tree: ast.AST) -> Dict[str, Any]:",
        "    \"\"\"Calculate code complexity metrics.\"\"\"",
        "    visitor = ComplexityVisitor()",
        "    visitor.visit(tree)",
        "    ",
        "    return {",
        "        \"total_complexity\": visitor.complexity,",
        "        \"function_complexities\": visitor.functions,",
        "        \"average_function_complexity\": (",
        "            sum(f[\"complexity\"] for f in visitor.functions) / len(visitor.functions)",
        "            if visitor.functions else 0",
        "        ),",
        "        \"high_complexity_functions\": [",
        "            f for f in visitor.functions if f[\"complexity\"] > 10",
        "        ]",
        "    }"
      ],
      "description": "Create code complexity calculator"
    }
  }   